{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9f0RSeUJLP1"
   },
   "source": [
    "*Problem Statement:*\n",
    "\n",
    "    Implement anomaly detection for given credit card dataset using Autoencoder and build the model by using the following steps:\n",
    "    a.\tImport required libraries\n",
    "    b.\tUpload / access the dataset\n",
    "    c.\tEncoder converts it into latent representation\n",
    "    d.\tDecoder networks convert it back to the original input\n",
    "    e.\tCompile the models with Optimizer, Loss, and Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEl3ncgPc0sv"
   },
   "source": [
    "\n",
    "#Credit Card Fraud Detection\n",
    "\n",
    "Example of outlier detection with autoencoders. Dataset https://www.kaggle.com/mlg-ulb/creditcardfraud from Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles).\n",
    "\n",
    "It is a highly unbalanced dataset with a very low percetnage of fraudulent credit card transactions. Our purpose is to build a classifier for detecting fraudulent transactions. In this example we will consider them as outliers an will use an autoencoder for detecting them.\n",
    "\n",
    "##Downloading of dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "gT2psZNVvB9U",
    "outputId": "2a781f3d-7b0e-4940-e228-0e87063f5f61"
   },
   "outputs": [],
   "source": [
    "#!wget -O creditfraud.zip https://www.dropbox.com/s/tl20yp9bcl56oxt/creditcardfraud.zip?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "1xqM1qxSvD_b",
    "outputId": "fd7ee9ea-45fe-4541-f214-ef496b71bc9f"
   },
   "outputs": [],
   "source": [
    "#!unzip creditfraud.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OV8v985dDi6"
   },
   "source": [
    "##Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "id": "C-vN7SvXvMs5",
    "outputId": "d0c3b824-37dc-41ee-f53f-33d3aed20442"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fp9PNETFd2G4"
   },
   "source": [
    "##Loading dataset in Python and taking a first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "NMVr2-hzvlID",
    "outputId": "c5d8f7c4-825b-40fd-cbb7-edc9a05804c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat=pd.read_csv('E:\\pict\\sem7\\lp4\\datasets\\creditcard.csv')\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y0a-xNMeDEA"
   },
   "source": [
    "The dataset is highly unbalanced with very few fraudulent credit cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "l3TwIbGCvmz9",
    "outputId": "1846477b-f926-4228-abe7-50146d09f04d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['Class'].value_counts()/dat['Class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "L4KRErdPvt1A",
    "outputId": "95e08e75-11e6-47f8-c377-4d3e7895728d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Class',data=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wDJt4sXDvxzb"
   },
   "outputs": [],
   "source": [
    "dat = dat.drop([ 'Time'], 1)\n",
    "dat['Amount'] = StandardScaler().fit_transform(dat['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vTh-X3beLk_"
   },
   "source": [
    "Splitting into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1T3X-3wFv001"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dat.drop('Class',1) , dat['Class'], test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "ooXM9UEwv3QX",
    "outputId": "0de04af5-f7fc-4d25-a8ed-1b349703a8ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998294\n",
       "1    0.001706\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()/y_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "K3YUftDjv5z-",
    "outputId": "247b9428-51e2-4c19-b3ac-398955f36455"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998251\n",
       "1    0.001749\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/y_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otvOl-HcevoG"
   },
   "source": [
    "##First method: using autoencoder's regression error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPpRAl0TeQR8"
   },
   "source": [
    "For our first example we will train our autoencoder only on non fraudulent cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mMzBdaAdv7rE"
   },
   "outputs": [],
   "source": [
    "X_train_normal = X_train[y_train==0]\n",
    "X_train_fraud = X_train[y_train==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbX1U5aheSla"
   },
   "source": [
    "Building an autoencoder with\n",
    "- an input layer with 29 neurons,\n",
    "- a hidden layer with 12 neurons,\n",
    "- an output layer with 29 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "euBPgiamw2R6",
    "outputId": "afd64cdc-dcf4-4595-9496-cc3b0d89fa0d"
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(29, ))\n",
    "encoded = Dense(12,activation='tanh')(input_layer)\n",
    "decoded = Dense(29,activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_layer,decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "fY42GWDWyoxL",
    "outputId": "ba09f0c7-e251-47c0-a269-f4af57513e33"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZC2j3eXJxM-B",
    "outputId": "87fb0776-1173-4a98-cd16-dd8da40fae7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1111/1111 [==============================] - 11s 10ms/step - loss: 0.8238 - val_loss: 0.8166\n",
      "Epoch 2/100\n",
      "1111/1111 [==============================] - 10s 9ms/step - loss: 0.8115 - val_loss: 0.8067\n",
      "Epoch 3/100\n",
      "1111/1111 [==============================] - 14s 13ms/step - loss: 0.8031 - val_loss: 0.7997\n",
      "Epoch 4/100\n",
      "1111/1111 [==============================] - 15s 13ms/step - loss: 0.7971 - val_loss: 0.7944\n",
      "Epoch 5/100\n",
      "1111/1111 [==============================] - 16s 14ms/step - loss: 0.7924 - val_loss: 0.7904\n",
      "Epoch 6/100\n",
      "1111/1111 [==============================] - 15s 13ms/step - loss: 0.7889 - val_loss: 0.7874\n",
      "Epoch 7/100\n",
      "1111/1111 [==============================] - 16s 14ms/step - loss: 0.7862 - val_loss: 0.7850\n",
      "Epoch 8/100\n",
      "1111/1111 [==============================] - 15s 14ms/step - loss: 0.7842 - val_loss: 0.7833\n",
      "Epoch 9/100\n",
      "1111/1111 [==============================] - 16s 14ms/step - loss: 0.7825 - val_loss: 0.7816\n",
      "Epoch 10/100\n",
      "1111/1111 [==============================] - 16s 14ms/step - loss: 0.7810 - val_loss: 0.7802\n",
      "Epoch 11/100\n",
      "1111/1111 [==============================] - 15s 14ms/step - loss: 0.7795 - val_loss: 0.7787\n",
      "Epoch 12/100\n",
      "1111/1111 [==============================] - 14s 12ms/step - loss: 0.7780 - val_loss: 0.7773\n",
      "Epoch 13/100\n",
      "1111/1111 [==============================] - 15s 13ms/step - loss: 0.7768 - val_loss: 0.7762\n",
      "Epoch 14/100\n",
      "1111/1111 [==============================] - 11s 10ms/step - loss: 0.7758 - val_loss: 0.7752\n",
      "Epoch 15/100\n",
      "1111/1111 [==============================] - 16s 14ms/step - loss: 0.7749 - val_loss: 0.7747\n",
      "Epoch 16/100\n",
      "1111/1111 [==============================] - 11s 10ms/step - loss: 0.7741 - val_loss: 0.7737\n",
      "Epoch 17/100\n",
      "1111/1111 [==============================] - 10s 9ms/step - loss: 0.7735 - val_loss: 0.7733\n",
      "Epoch 18/100\n",
      "1111/1111 [==============================] - 10s 9ms/step - loss: 0.7731 - val_loss: 0.7727\n",
      "Epoch 19/100\n",
      "1111/1111 [==============================] - 10s 9ms/step - loss: 0.7727 - val_loss: 0.7727\n",
      "Epoch 20/100\n",
      "1111/1111 [==============================] - 9s 8ms/step - loss: 0.7723 - val_loss: 0.7720\n",
      "Epoch 21/100\n",
      "1111/1111 [==============================] - 8s 7ms/step - loss: 0.7719 - val_loss: 0.7718\n",
      "Epoch 22/100\n",
      "1111/1111 [==============================] - 9s 8ms/step - loss: 0.7716 - val_loss: 0.7713\n",
      "Epoch 23/100\n",
      "1111/1111 [==============================] - 11s 10ms/step - loss: 0.7714 - val_loss: 0.7712\n",
      "Epoch 24/100\n",
      "1111/1111 [==============================] - 13s 11ms/step - loss: 0.7711 - val_loss: 0.7711\n",
      "Epoch 25/100\n",
      "1111/1111 [==============================] - 15s 14ms/step - loss: 0.7710 - val_loss: 0.7708\n",
      "Epoch 26/100\n",
      "1111/1111 [==============================] - 14s 12ms/step - loss: 0.7707 - val_loss: 0.7707\n",
      "Epoch 27/100\n",
      "1111/1111 [==============================] - 9s 8ms/step - loss: 0.7705 - val_loss: 0.7704\n",
      "Epoch 28/100\n",
      "1111/1111 [==============================] - 9s 8ms/step - loss: 0.7704 - val_loss: 0.7704\n",
      "Epoch 29/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7702 - val_loss: 0.7700\n",
      "Epoch 30/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7701 - val_loss: 0.7698\n",
      "Epoch 31/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7699 - val_loss: 0.7697\n",
      "Epoch 32/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7698 - val_loss: 0.7696\n",
      "Epoch 33/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7697 - val_loss: 0.7695\n",
      "Epoch 34/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7696 - val_loss: 0.7694\n",
      "Epoch 35/100\n",
      "1111/1111 [==============================] - 18s 17ms/step - loss: 0.7694 - val_loss: 0.7694\n",
      "Epoch 36/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7693 - val_loss: 0.7694\n",
      "Epoch 37/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7692 - val_loss: 0.7690\n",
      "Epoch 38/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7691 - val_loss: 0.7693\n",
      "Epoch 39/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7690 - val_loss: 0.7688\n",
      "Epoch 40/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7689 - val_loss: 0.7688\n",
      "Epoch 41/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7688 - val_loss: 0.7689\n",
      "Epoch 42/100\n",
      "1111/1111 [==============================] - 11s 10ms/step - loss: 0.7688 - val_loss: 0.7687\n",
      "Epoch 43/100\n",
      "1111/1111 [==============================] - 9s 8ms/step - loss: 0.7686 - val_loss: 0.7686\n",
      "Epoch 44/100\n",
      "1111/1111 [==============================] - 9s 8ms/step - loss: 0.7686 - val_loss: 0.7685\n",
      "Epoch 45/100\n",
      "1111/1111 [==============================] - 8s 7ms/step - loss: 0.7685 - val_loss: 0.7683\n",
      "Epoch 46/100\n",
      "1111/1111 [==============================] - 9s 8ms/step - loss: 0.7684 - val_loss: 0.7686\n",
      "Epoch 47/100\n",
      "1111/1111 [==============================] - 21s 19ms/step - loss: 0.7684 - val_loss: 0.7683\n",
      "Epoch 48/100\n",
      "1111/1111 [==============================] - 17s 15ms/step - loss: 0.7683 - val_loss: 0.7682\n",
      "Epoch 49/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7682 - val_loss: 0.7681\n",
      "Epoch 50/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7681 - val_loss: 0.7680\n",
      "Epoch 51/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7681 - val_loss: 0.7681\n",
      "Epoch 52/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7680 - val_loss: 0.7680\n",
      "Epoch 53/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7680 - val_loss: 0.7679\n",
      "Epoch 54/100\n",
      "1111/1111 [==============================] - 15s 13ms/step - loss: 0.7680 - val_loss: 0.7679\n",
      "Epoch 55/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7679 - val_loss: 0.7679\n",
      "Epoch 56/100\n",
      "1111/1111 [==============================] - 17s 15ms/step - loss: 0.7678 - val_loss: 0.7677\n",
      "Epoch 57/100\n",
      "1111/1111 [==============================] - 16s 15ms/step - loss: 0.7677 - val_loss: 0.7677\n",
      "Epoch 58/100\n",
      "1111/1111 [==============================] - 14s 12ms/step - loss: 0.7677 - val_loss: 0.7678\n",
      "Epoch 59/100\n",
      "1111/1111 [==============================] - 26s 23ms/step - loss: 0.7677 - val_loss: 0.7676\n",
      "Epoch 60/100\n",
      "1111/1111 [==============================] - 15s 14ms/step - loss: 0.7676 - val_loss: 0.7674\n",
      "Epoch 61/100\n",
      "1111/1111 [==============================] - 27s 25ms/step - loss: 0.7676 - val_loss: 0.7674\n",
      "Epoch 62/100\n",
      "1111/1111 [==============================] - 28s 25ms/step - loss: 0.7676 - val_loss: 0.7676\n",
      "Epoch 63/100\n",
      "1111/1111 [==============================] - 29s 26ms/step - loss: 0.7675 - val_loss: 0.7675\n",
      "Epoch 64/100\n",
      "1111/1111 [==============================] - 30s 27ms/step - loss: 0.7675 - val_loss: 0.7673\n",
      "Epoch 65/100\n",
      "1111/1111 [==============================] - 30s 27ms/step - loss: 0.7674 - val_loss: 0.7673\n",
      "Epoch 66/100\n",
      "1111/1111 [==============================] - 28s 26ms/step - loss: 0.7673 - val_loss: 0.7675\n",
      "Epoch 67/100\n",
      "1111/1111 [==============================] - 29s 26ms/step - loss: 0.7673 - val_loss: 0.7673\n",
      "Epoch 68/100\n",
      "1111/1111 [==============================] - 27s 25ms/step - loss: 0.7674 - val_loss: 0.7671\n",
      "Epoch 69/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7672 - val_loss: 0.7675\n",
      "Epoch 70/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7673 - val_loss: 0.7671\n",
      "Epoch 71/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7672 - val_loss: 0.7672\n",
      "Epoch 72/100\n",
      "1111/1111 [==============================] - 9s 8ms/step - loss: 0.7672 - val_loss: 0.7672\n",
      "Epoch 73/100\n",
      "1111/1111 [==============================] - 17s 15ms/step - loss: 0.7671 - val_loss: 0.7674\n",
      "Epoch 74/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7671 - val_loss: 0.7671\n",
      "Epoch 75/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7671 - val_loss: 0.7670\n",
      "Epoch 76/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7670 - val_loss: 0.7670\n",
      "Epoch 77/100\n",
      "1111/1111 [==============================] - 17s 16ms/step - loss: 0.7670 - val_loss: 0.7670\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111/1111 [==============================] - 21s 19ms/step - loss: 0.7670 - val_loss: 0.7668\n",
      "Epoch 79/100\n",
      "1111/1111 [==============================] - 22s 20ms/step - loss: 0.7669 - val_loss: 0.7669\n",
      "Epoch 80/100\n",
      "1111/1111 [==============================] - 21s 19ms/step - loss: 0.7670 - val_loss: 0.7668\n",
      "Epoch 81/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7669 - val_loss: 0.7667\n",
      "Epoch 82/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7668 - val_loss: 0.7669\n",
      "Epoch 83/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7669 - val_loss: 0.7667\n",
      "Epoch 84/100\n",
      "1111/1111 [==============================] - 22s 20ms/step - loss: 0.7668 - val_loss: 0.7667\n",
      "Epoch 85/100\n",
      "1111/1111 [==============================] - 21s 19ms/step - loss: 0.7668 - val_loss: 0.7669\n",
      "Epoch 86/100\n",
      "1111/1111 [==============================] - 21s 19ms/step - loss: 0.7668 - val_loss: 0.7667\n",
      "Epoch 87/100\n",
      "1111/1111 [==============================] - 20s 18ms/step - loss: 0.7667 - val_loss: 0.7666\n",
      "Epoch 88/100\n",
      "1111/1111 [==============================] - 15s 14ms/step - loss: 0.7668 - val_loss: 0.7667\n",
      "Epoch 89/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7667 - val_loss: 0.7666\n",
      "Epoch 90/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7667 - val_loss: 0.7665\n",
      "Epoch 91/100\n",
      "1111/1111 [==============================] - 17s 15ms/step - loss: 0.7667 - val_loss: 0.7666\n",
      "Epoch 92/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7666 - val_loss: 0.7665\n",
      "Epoch 93/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7667 - val_loss: 0.7666\n",
      "Epoch 94/100\n",
      "1111/1111 [==============================] - 21s 19ms/step - loss: 0.7666 - val_loss: 0.7668\n",
      "Epoch 95/100\n",
      "1111/1111 [==============================] - 22s 19ms/step - loss: 0.7666 - val_loss: 0.7665\n",
      "Epoch 96/100\n",
      "1111/1111 [==============================] - 19s 17ms/step - loss: 0.7666 - val_loss: 0.7666\n",
      "Epoch 97/100\n",
      "1111/1111 [==============================] - 21s 19ms/step - loss: 0.7666 - val_loss: 0.7664\n",
      "Epoch 98/100\n",
      "1111/1111 [==============================] - 18s 16ms/step - loss: 0.7666 - val_loss: 0.7666\n",
      "Epoch 99/100\n",
      "1111/1111 [==============================] - 21s 19ms/step - loss: 0.7664 - val_loss: 0.7664\n",
      "Epoch 100/100\n",
      "1111/1111 [==============================] - 21s 19ms/step - loss: 0.7664 - val_loss: 0.7666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x50be10bac0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train_normal, X_train_normal, epochs = 100, batch_size=128,\n",
    "validation_data=(X_train_normal,X_train_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "qzcu7y3nxsw3",
    "outputId": "d1f73fe7-8c35-402d-9123-c63bf2d2a8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4451/4451 [==============================] - 28s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">reconstruction_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142154.0</td>\n",
       "      <td>0.766624</td>\n",
       "      <td>3.452137</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>0.226929</td>\n",
       "      <td>0.389378</td>\n",
       "      <td>0.643959</td>\n",
       "      <td>319.575647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249.0</td>\n",
       "      <td>30.130602</td>\n",
       "      <td>43.295584</td>\n",
       "      <td>0.114217</td>\n",
       "      <td>4.172876</td>\n",
       "      <td>10.612298</td>\n",
       "      <td>27.190596</td>\n",
       "      <td>280.467545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reconstruction_error                                            \\\n",
       "                          count       mean        std       min       25%   \n",
       "true_class                                                                  \n",
       "0                      142154.0   0.766624   3.452137  0.036334  0.226929   \n",
       "1                         249.0  30.130602  43.295584  0.114217  4.172876   \n",
       "\n",
       "                                              \n",
       "                  50%        75%         max  \n",
       "true_class                                    \n",
       "0            0.389378   0.643959  319.575647  \n",
       "1           10.612298  27.190596  280.467545  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = autoencoder.predict(X_train)\n",
    "mse = np.mean(np.power(X_train - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_train})\n",
    "error_df.groupby('true_class').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRQepwFre9UM"
   },
   "source": [
    "As we can see above the error for non fraudulent case is lower than the error for fraudulent cases. We use a threshold of mean plus 3 sds to classify the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-zAII8DQxw-B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4451/4451 [==============================] - 15s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions=autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - test_predictions, 2), axis=1)\n",
    "y_pred=[(lambda er: 1 if er>=11.078922  else 0)(er) for er in mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "mZ4V1lfb46jQ",
    "outputId": "ddd09775-e18f-411a-bf83-4204e1a7bfef"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAro0lEQVR4nO3debxd873/8dc7iUQMiUzcNAkJohoqmhBDW0UMMYaa0lK5mv5SQ3HbalEuRV3VVqnb0htVhBLDNcQlpqBoY0gIEVNSikiQyIBEJeecz++P9T2xc+ycs8+wz7TeT4/1OGt/1/qu73fnHPuzv8P6LkUEZmaWXx1augJmZtayHAjMzHLOgcDMLOccCMzMcs6BwMws5xwIzMxyzoHAGk1SV0l3S1om6dZGXOdoSQ80Zd1agqQpksa2dD3MSuVAkCOSvi1puqSPJS1IH1hfa4JLHw5sAvSKiCMaepGI+EtE7NME9VmDpN0lhaTba6QPTemPlnidn0u6oa7zImK/iLiugdU1a3YOBDkh6UfAZcB/kX1obwpcAYxugstvBrwWERVNcK1yWQjsKqlXQdpY4LWmKkAZ/z9lbY7/aHNAUnfgfOCkiLg9IpZHxKqIuDsifpLO6SLpMknz03aZpC7p2O6S5kn6saT3U2viuHTsPOAc4KjU0hhX85uzpIHpm3en9PrfJb0u6SNJb0g6uiD9iYJ8u0p6JnU5PSNp14Jjj0q6QNLf0nUekNS7ln+GlcCdwJiUvyNwJPCXGv9Wv5P0tqQPJc2Q9PWUPgr4WcH7fL6gHhdK+huwAtg8pX0vHb9S0m0F179Y0lRJKvX3Z1ZuDgT5sAuwLnBHLeecBewMbA8MBUYAZxcc/zegO9APGAf8QVKPiDiXrJVxc0RsEBFX11YRSesDlwP7RcSGwK7AzCLn9QTuSef2An4L3FPjG/23geOAjYHOwGm1lQ1MBI5N+/sCs4H5Nc55huzfoCdwI3CrpHUj4r4a73NoQZ7vAOOBDYE3a1zvx8B2Kch9nezfbmx4bRdrRRwI8qEXsKiOrpujgfMj4v2IWAicR/YBV21VOr4qIu4FPga+2MD6VAHbSuoaEQsiYnaRcw4A5kTE9RFRERE3Aa8ABxWcc01EvBYRnwC3kH2Ar1VE/B3oKemLZAFhYpFzboiID1KZlwBdqPt9XhsRs1OeVTWutwI4hiyQ3QCcHBHz6rieWbNyIMiHD4De1V0za/EF1vw2+2ZKW32NGoFkBbBBfSsSEcuBo4DjgQWS7pG0dQn1qa5Tv4LX7zagPtcDPwD2oEgLKXV/vZy6o5aStYJq63ICeLu2gxHxNPA6ILKAZdaqOBDkwzTgX8AhtZwzn2zQt9qmfL7bpFTLgfUKXv9b4cGIuD8i9gb6kn3Lv6qE+lTX6Z0G1qna9cCJwL3p2/pqqevmdLKxgx4RsRGwjOwDHGBt3Tm1dvNIOomsZTEf+GmDa25WJg4EORARy8gGdP8g6RBJ60laR9J+kn6VTrsJOFtSnzToeg5ZV0ZDzAR2k7RpGqg+s/qApE0kHZzGCj4l62KqLHKNe4Gt0pTXTpKOAoYA/9fAOgEQEW8A3yAbE6lpQ6CCbIZRJ0nnAN0Kjr8HDKzPzCBJWwG/IOse+g7wU0nbN6z2ZuXhQJATEfFb4EdkA8ALybozfkA2kwayD6vpwAvALODZlNaQsh4Ebk7XmsGaH94dyAZQ5wOLyT6UTyxyjQ+AA9O5H5B9kz4wIhY1pE41rv1ERBRr7dwPTCGbUvomWSuqsNun+ma5DyQ9W1c5qSvuBuDiiHg+IuaQzTy6vnpGlllrIE9eMDPLN7cIzMxyzoHAzCznHAjMzHLOgcDMrIlJ+nNajuXFIsdOS0uu9C5IO1PSXEmvStq3IH24pFnp2OXVS5OkJWFuTulPSRpYkGespDlpK2kV3NpuMGpRqxa97lFs+5z1vvD1lq6CtUKrVr7T6LWb6vOZs07vzesq71rg99S4e13SAGBv4K2CtCFka2BtQ3Yj5UOStoqISuBKsuVLniSbUj2KbGbbOGBJRGwpaQxwMdk6WD2Bc4EdyO5vmSFpckQsqa2ybhGYmTWxiHiMbHp0TZeSTYUuDDqjgUkR8Wm6z2UuMEJSX6BbRExLa1NN5LObQkcD1Uud3waMTK2FfYEHI2Jx+vB/kCx41KrVtgjMzJpVVbH7GpuOpIOBdyLi+RqLz/Yj+8ZfbV5KW5X2a6ZX53kbICIqJC0jW1NsdXqRPGvlQGBmBlBZ+uM0JI0n67KpNiEiJtRy/npkd7MXe/BSsW6mqCW9oXnWyoHAzAyIqKrHuTEBWOsHfxFbAIOA6tZAf+BZSSPIvrUPKDi3P9md9/PSfs10CvLMS3ewdyfripoH7F4jz6N1Vc5jBGZmAFVVpW/1FBGzImLjiBgYEQPJPrCHRcS7wGRgTJoJNAgYDDwdEQuAjyTtnPr/jwXuSpecTPaEPcgeFftwGke4H9hHUg9JPchaIPfXVT+3CMzMAOrRIqiLpJvIvpn3ljQPOHdtD22KiNmSbgFeIlv08KQ0YwjgBLIZSF3JZgtNSelXk61ZNZesJTAmXWuxpAvIHrAE2TNEig1ar1nf1rrWkKePWjGePmrFNMX00ZVvPlvyZ07nzYa1q0eNukVgZgZN2iJoaxwIzMyAqMesofbGgcDMDBo0CNxeOBCYmYG7hszMcq/Mdxa3Zg4EZmbgFoGZWe55sNjMLOc8WGxmlm+f3cybPw4EZmbgMQIzs9xz15CZWc65RWBmlnOVq1q6Bi3GgcDMDNw1ZGaWe+4aMjPLObcIzMxyzoHAzCzfwoPFZmY55zECM7Occ9eQmVnOuUVgZpZzOW4RdGjpCpiZtQpRVfpWB0l/lvS+pBcL0n4t6RVJL0i6Q9JGBcfOlDRX0quS9i1IHy5pVjp2uSSl9C6Sbk7pT0kaWJBnrKQ5aRtbylt3IDAzA6ioKH2r27XAqBppDwLbRsR2wGvAmQCShgBjgG1SniskdUx5rgTGA4PTVn3NccCSiNgSuBS4OF2rJ3AusBMwAjhXUo+6KutAYGYGTdoiiIjHgMU10h6IiOoo8iTQP+2PBiZFxKcR8QYwFxghqS/QLSKmRUQAE4FDCvJcl/ZvA0am1sK+wIMRsTgilpAFn5oB6XMcCMzMIBsjKHGTNF7S9IJtfD1L+y4wJe33A94uODYvpfVL+zXT18iTgssyoFct16qVB4vNzKBes4YiYgIwoSHFSDoLqAD+Up1UrIha0huaZ63cIjAzg3q1CBoqDd4eCBydunsg+9Y+oOC0/sD8lN6/SPoaeSR1ArqTdUWt7Vq1ciAwM4MmHSMoRtIo4HTg4IhYUXBoMjAmzQQaRDYo/HRELAA+krRz6v8/FrirIE/1jKDDgYdTYLkf2EdSjzRIvE9Kq5W7hszMoNTZQCWRdBOwO9Bb0jyymTxnAl2AB9Ms0Ccj4viImC3pFuAlsi6jkyKiMl3qBLIZSF3JxhSqxxWuBq6XNJesJTAGICIWS7oAeCadd35ErDFoXbS+n7VOWpdVi15vnRWzFrXeF77e0lWwVmjVyneK9Y3Xyyc3n1fyZ07Xo85tdHmtiVsEZmaQ6zuLHQjMzMCBwMws97zonJlZzlVW1n1OO+VAYGYG7hoyM8s9BwIzs5zzGIGZWb5FVX5vXXIgMDMDdw2ZmeWeZw2ZmeWcWwRmZjmX40DgZajL6Oz/+i27HTCGQ445/nPHrrnxNrb96n4sWboMgKXLPuS4H5zOjnsdyoWXXLHGud//0dl8c+yJjD76+5z3q/+mMjVh57/7HuNOOYNDjz2Bf//BT3n3/YUAvPLaPzh6/A8ZffT3OfTYE5jy0F/L/E6tqW211RZMf+aB1dsHi17hlJO/B8BJJx7Hiy8+xsyZD3PRRWcBsM466/Cnq37Lc88+xIzpD7Lbbru0ZPXbpojSt3bGLYIyOmT/vfn2YQfzswt+s0b6gvcWMu2Z5+i7ycar0zp37szJ/+87zHn9Tea+/uYa519ywZlssP76RAQ/POtC7n/kcfbfa3d+8/s/cfCokYzef2+emjGTy/54Lb885yesu24X/us/T2OzAf14f+EHHDnuZL6603C6bbhBs7xva7zXXvsHO+y4DwAdOnTgzX/O4M67pvCNb+zKQQfty7Bhe7Fy5Ur69OkFwPfGfRuArwzbiz59evF/d9/AzrvsT2tdXbhVcovAymGH7b9M924bfi79V5f/Dz86cRwqWMh2va7rMmzotnTp3Plz52+w/voAVFRWsqpiFUpPo/vHG2+x0w7bAzBi2FAeeXwaAAM37c9mA7LHlG7cpxc9e2y0uuVhbc+ee36N119/k7feeofvf/9YfvXrP7By5UoAFi78AIAvfWkrHn7kidVpS5d+yA7Dh7ZYndukqih9a2fKEggkDattK0eZbcUjjz/Jxn16s/XgzeuVb/wPz+IbB36L9ddbj332+BoAXxy8OQ8++jcAHvrr31m+4hOWLvtwjXyzXnqVVasqGNCvb9O8AWt2Rx05mptvvhOArQZvzte+NoK/PXE3Ux+6bfWH/QsvvMRBB+1Lx44dGThwAMOGfZn+A77QgrVugyorS9/amXJ1DV1Sy7EA9ix2QNJ4YDzAFZf8gu8d+60yVK3lfPKvfzFh4iQmXHphvfNOuPRCPv10Jaef9yuemvE8u44YxmknfY8Lf3sFd937IMO3/zKb9OlFx44dV+dZuGgxZ57/ay48+8d06ODGX1u0zjrrcOCB+3DW2RcB0LFTR3ps1J2vfu0gdtxhe2688Y9s9cVduObaSWy99WCeenIKb741j2nTplPRhE/cyoPIcddQWQJBROzRwHwTgAnQPp9Q9vY7C3hn/rscNvZEAN5buIgjvnsyk666jN69etaZv0uXzuzxtZ145PEn2XXEMDbu04vfXfSfAKxY8QkPPfoEG26QdSN9vHw5J/7kHE4eP5ah236pfG/KymrUqD147rlZvP/+IgDembeAO+7Mnlb4zPSZVFVV0bt3TxYtWsxpP/n56nyP/fUu5s59oyWq3Ha1wy6fUpV9sFjStsAQYN3qtIiYWO5yW6OtthjEY/dMWv16n8PGcvPVl9Njo+5rzbNixScsX/EJfXr3pKKiksemTWf40G0AWLJ0Gd27bUiHDh246vqbOfSAbHBx1apVnHrmBRw8aiT77ulHO7ZlRx11yOpuIYDJk+9njz2+ymOPTWPw4M3p3LkzixYtpmvXdZHEihWfMHLk16moqODll+e0XMXbIq81VB6SziV7gPMQ4F5gP+AJIBeB4Cfn/pJnnnuBpUs/ZOQhx3DiuO9w2EH7rvX8fQ4by8fLV7CqooKHH/87Ey69kO7du/GD03/OylWrqKqsYqfhQznykAMAeOa5F7jsj9ciieFDt+XsH2ctjfsefpwZM19k6bKPuPPehwC48KwfsfVWW5T/TVuT6dp1XfYauRsnnnj66rRrrp3En666hOeem8qqlav47rj/AGDjjXtzzz03UlVVxfx33uXfjzulhWrdhuW4RVDWh9dLmgUMBZ6LiKGSNgH+FBEH1ZW3PXYNWeP54fVWTFM8vH75OWNK/sxZ//xJfnh9PXwSEVWSKiR1A94H6jddxsysOeS4a6jcU0mmS9oIuAqYATwLPF3mMs3M6q8J7yOQ9GdJ70t6sSCtp6QHJc1JP3sUHDtT0lxJr0ratyB9uKRZ6djlUnb3kaQukm5O6U9JGliQZ2wqY46ksaW89bIGgog4MSKWRsQfgb2BsRFxXDnLNDNriKiqKnkrwbXAqBppZwBTI2IwMDW9RtIQYAywTcpzhaTqeeBXkk2pH5y26muOA5ZExJbApcDF6Vo9gXOBnYARwLmFAWdtyj65XNJ2kg4GhgFbSvpmucs0M6u3JmwRRMRjwOIayaOB69L+dcAhBemTIuLTiHgDmAuMkNQX6BYR0yIbzJ1YI0/1tW4DRqbWwr7AgxGxOCKWAA/y+YD0OeWeNfRnYDtgNlAdRgO4vZzlmpnVWz1mDRXe/JpMSPdB1WaTiFgAEBELJFUvNtYPeLLgvHkpbVXar5leneftdK0KScuAXoXpRfKsVbkHi3eOiCFlLsPMrPHqsXRE4c2vTaDYDKSoJb2hedaq3F1D01L/l5lZqxZVUfLWQO+l7h7Sz/dT+jxgQMF5/YH5Kb1/kfQ18kjqBHQn64pa27VqVe5AcB1ZMHhV0gtp9PuFMpdpZlZ/5V99dDJQPYtnLHBXQfqYNBNoENmg8NOpG+kjSTun/v9ja+SpvtbhwMNpHOF+YB9JPdIg8T4prVbl7hr6M/AdYBafjRGYmbU+TbjonKSbyFZV6C1pHtlMnl8Ct0gaB7wFHAEQEbMl3QK8BFQAJ0VEdT/VCWQzkLoCU9IGcDVwvaS5ZC2BMelaiyVdADyTzjs/ImoOWn++vmW+s/jhiCi60mhdfGexFeM7i62Ypriz+KMT9yv5M2fDK6b4zuJ6eEXSjcDdwKfViRHhWUNm1rrkeK2hcgeCrmQBYJ+CNE8fNbNWJyrz23tdtkCQ7oxbFBE/KVcZZmZNxi2CphcRlXl/LKWZtR2NmBba5pW7a2impMnArcDy6kSPEZhZq+NAUDY9gQ9Y8xnFHiMws9Ynv0ME5Q0EXmnUzNqKqMhvJCjrncWS+ku6I63L/Z6k/5XUv+6cZmbNrKoeWztT7iUmriG7FfoLZCvg3Z3SzMxalWZYa6jVKncg6BMR10RERdquBfqUuUwzs/pzi6BsFkk6RlLHtB1DNnhsZtaquEVQPt8FjgTeBRaQrZL33TKXaWZWfzluEZR71tBbwMHlLMPMrClERUvXoOWUJRBIOqeWwxERF5SjXDOzhop2+E2/VPXqGkoPO9iuhFOXF9kAxgGn16uGZmbNwV1DayfpUbLunU7ATGChpL9GxI/WliciLinIvyFwKnAcMAm4ZG35zMxailsEteseER8C3wSuiYjhwF51ZZLUU9IvgBfIgsiwiDg9It6vI6uZWbOLqtK39qaUMYJO6UHLRwJnlXJRSb8mCxwTgC9HxMcNr6KZWflFZbt66Fi9lNIiOJ/s4cdzI+IZSZsDc+rI82Oyu4nPBuZL+jBtH0n6sHFVNjNrem4R1CIibiVbRrr69evAYXXkKff9CWZmTSqq8tsiWGsgkPTfZEtGFxURp5SlRmZmLaA9ftMvVW0tgunNVgszsxYW4RbB50TEdYWvJa0fEcvXdr6ZWVvWlC0CST8EvkfWqzKLbPr8esDNwEDgn8CREbEknX8m2X1WlcApEXF/Sh8OXAt0Be4FTo2IkNQFmAgMJ1u/7aiI+GdD61tnX76kXSS9BLycXg+VdEVDCzQza42qKlXyVhtJ/YBTgB0iYlugIzAGOAOYGhGDganpNZKGpOPbAKOAKyR1TJe7EhgPDE7bqJQ+DlgSEVsClwIXN+a9lzKoexmwL2nV0Ih4HtitMYWambU2UaWStxJ0ArpK6kTWEpgPjAaqe1quAw5J+6OBSRHxaUS8AcwFRqRp+90iYlpEBFkLoDBP9bVuA0ZKanDfVkmzeyLi7RpJlQ0t0MysNapPIJA0XtL0gm386utEvAP8BniLbNXlZRHxALBJRCxI5ywANk5Z+gGFn7HzUlq/tF8zfY08EVEBLAN6NfS9l3JD2duSdgVCUmeyJs/LDS3QzKw1ino8ZiAiJpDdMPs5knqQfWMfBCwFbk3PYlmbYt/ko5b02vI0SCktguOBk8gi0DvA9um1mVm70YRdQ3sBb0TEwohYBdwO7Aq8l7p7SD+rl9uZBwwoyN+frCtpXtqvmb5GntT91B1Y3MC3XncgiIhFEXF0RGwSEX0i4piI8FPGzKxdiVDJWx3eAnaWtF7qtx9J1osyGRibzhkL3JX2JwNjJHWRNIhsUPjp1H30kaSd03WOrZGn+lqHAw+ncYQGKWX10c2B3wE7kzU9pgE/THcYm5m1C5VNtNZQRDwl6TbgWaACeI6sG2kD4BZJ48iCxRHp/NmSbgFeSuefFBHV47An8Nn00SlpA7gauF7SXLKWwJjG1Fl1BRFJTwJ/AG5KSWOAkyNip8YUXJdVi15vfw8GtUZb7wtfb+kqWCu0auU7jf4Uf3Xr/Ur+zPniK1Pa1d1npYwRKCKuj4iKtN1AIwYlzMxaoyaePtqm1LbWUM+0+4ikM8geKhPAUcA9zVA3M7Nm0/Ae9ravtjGCGaw5hen7BccC8HOHzazdaI/f9EtV21pDg5qzImZmLamyKr+r55dyQxmStgWGAOtWp0XExHJVysysublrqBaSzgV2JwsE9wL7AU+QrXthZtYuVOV4GepS2kKHk90Q8W5EHAcMBbqUtVZmZs2sCW8oa3NK6Rr6JCKqJFVI6kZ2W/TmZa6XmVmzctdQ7aZL2gi4imwm0cfA0+WsFEBX3zhkZs0oz11DpTy8/sS0+0dJ95Gtj/1CeatlZta8PGuoCEnDajsWEc+Wp0pmZs0vxz1DtbYILqnlWAB7NnFdzMxajLuGioiIPZqzImZmLak9zgYqVUk3lJmZtXdVLV2BFuRAYGYGRNGnP+aDA4GZGVCR466hOudLKXOMpHPS600ljSh/1czMmk+gkrf2ppSJs1cAuwDfSq8/IntimZlZu1FVj629KaVraKeIGCbpOYCIWCKpc5nrZWbWrNrjN/1SlRIIVknqSLrfQlIf2mdQNLMcy/OHWimB4HLgDmBjSReSrUZ6dllrZWbWzCpz3CKoc4wgIv4C/BS4CFgAHBIRt5a7YmZmzalKpW91kbSRpNskvSLpZUm7SOop6UFJc9LPHgXnnylprqRXJe1bkD5c0qx07HJJSuldJN2c0p+SNLAx772UWUObAiuAu4HJwPKUZmbWblShkrcS/A64LyK2JnuGy8vAGcDUiBgMTE2vkTQEGANsA4wCrkjd8QBXAuOBwWkbldLHAUsiYkvgUuDixrz3UmYN3QP8X/o5FXgdmNKYQs3MWpuox1ab9NyW3YCrASJiZUQsBUYD16XTrgMOSfujgUkR8WlEvAHMBUZI6ku22vO0iAiyp0IW5qm+1m3AyOrWQkOUsgz1lwtfp1VJv9/QAs3MWqMmHCzeHFgIXCNpKNlzXE4FNomIBQARsUDSxun8fsCTBfnnpbRVab9menWet9O1KiQtA3oBixpS4XovwJ2Wn96xIYWZmbVWVVLJm6TxkqYXbOMLLtUJGAZcGRFfAZaTuoHWotg3+aglvbY8DVLKw+t/VPCyA9kbXNjQAs3MWqPKepwbEROACWs5PA+YFxFPpde3kQWC9yT1Ta2BvmSP/a0+f0BB/v7A/JTev0h6YZ55kjoB3YHF9XgLayilRbBhwdaFbKxgdEMLNDNrjZpq1lBEvAu8LemLKWkk8BLZZJuxKW0scFfanwyMSTOBBpENCj+dupE+krRz6v8/tkae6msdDjycxhEapNYWQRq53iAiftLQAszM2oISZwOV6mTgL2kVhteB48i+eN8iaRzwFnAEQETMlnQLWbCoAE6KiOoGygnAtUBXskk61RN1rgaulzSXrCUwpjGV1dqCiKROaRBiakSMbEwhDdGpc788PznOzOqhYuU7jf4Uv+ELx5T8mXPM/Bva1d1ntbUIniYbD5gpaTJwK9mgBwARcXuZ62Zm1mxKuVGsvSpliYmewAdkzyiuHskOwIHAzNoNrzVU3MZpxtCLfH4qk7ttzKxdqXSLoKiOwAY08XxVM7PWyC2C4hZExPnNVhMzsxbkQFBcjhtKZpY3OX5kca2BoNmnjJqZtRS3CIqIiAbfrmxm1tbUZ4mJ9qaU6aNmZu2e7yMwM8s5dw2ZmeWcA4GZWc7l+eYoBwIzMzxGYGaWe541ZGaWc1U57hxyIDAzw4PFZma5l9/2gAOBmRngFoGZWe5VKL9tAgcCMzPcNWRmlnvuGjIzy7k8Tx/t0NIVMDNrDaIeWykkdZT0nKT/S697SnpQ0pz0s0fBuWdKmivpVUn7FqQPlzQrHbtcklJ6F0k3p/SnJA1szHt3IDAzI+saKnUr0anAywWvzwCmRsRgYGp6jaQhwBhgG2AUcIWkjinPlcB4YHDaRqX0ccCSiNgSuBS4uD7vtSYHAjMzoJIoeauLpP7AAcCfCpJHA9el/euAQwrSJ0XEpxHxBjAXGCGpL9AtIqZFRAATa+SpvtZtwMjq1kJDOBCYmVG/FoGk8ZKmF2zja1zuMuCnrNmA2CQiFgCknxun9H7A2wXnzUtp/dJ+zfQ18kREBbAM6NWgN44Hi83MAIh6DBZHxARgQrFjkg4E3o+IGZJ2L+Fyxb7JRy3pteVpEAcCMzOadProV4GDJe0PrAt0k3QD8J6kvhGxIHX7vJ/OnwcMKMjfH5if0vsXSS/MM09SJ6A70ODnzLtrqBW4asIlzJ/3PDOfm7o67byf/4RnZzzI9GceYMo9N9K37yYA9OzZg4ceuJWli1/jd5f9oqWqbM2g2N/FYYcdyPMzH2blv95m+LDtVqfvNfLrPPXkFJ579iGeenIKe+z+1ZaocptWRZS81SYizoyI/hExkGwQ+OGIOAaYDIxNp40F7kr7k4ExaSbQILJB4adT99FHknZO/f/H1shTfa3DUxkNbhE4ELQCEyfewgEHHr1G2m8uuZJhw/dmhx334Z57H+Lss34IwL/+9S/O/fmv+OnpF7REVa0ZFfu7mD37FY448v/x+ONPrpG+6IPFHHLov/OVYXvx3XH/wbXX/K45q9ouNPX00SJ+CewtaQ6wd3pNRMwGbgFeAu4DToqI6scjnEA24DwX+AcwJaVfDfSSNBf4EWkGUkO5a6gVePyJp9hss/5rpH300cer99dffz2qg/2KFZ/wt78/wxZbDGrWOlrzK/Z38corc4ueO3Pm7NX7s2e/yrrrrkvnzp1ZuXJlWevYnlSU4YayiHgUeDTtfwCMXMt5FwIXFkmfDmxbJP1fwBFNVc+yBAJJPWs7HhEN7svKkwvOP51jjj6cZR9+yF57N9nv3Nq5b37zAGbOfNFBoJ7qM1jc3pSra2gGMD39XAi8BsxJ+zPWlqlwSlZV1fIyVa3t+M9zLmbQFjty0013cNKJx7V0dawNGDJkKy668GeccNLpLV2VNqcMN5S1GWUJBBExKCI2B+4HDoqI3hHRCzgQuL2WfBMiYoeI2KFDh/XLUbU26aZJd3Doofu3dDWslevXry+33Xo1x333VF5//c2Wrk6bE/X4r70p92DxjhFxb/WLiJgCfKPMZbYLW2752RjAQQfuw6uv/qMFa2OtXffu3Zh810TOOvsi/j5tektXp03Kc4tAjZhxVPfFpfuBx4EbyAbbjwF2i4h9a80IdOrcr/2F3bW44fo/8I3ddqF37568994izjv/N+y3355stdUWVFVV8dZb73DiSWcwf/67AMx97Um6dduAzp07s3Tph+x3wLd4+eU5LfwurKkV+7tYvGQpv7v0F/Tp05OlSz/k+edns/+BR/OzM0/l9J/+gDlz31idf7/9v8XChR+04DtoPhUr32nw8grVjtnsmyV/5tzw5u2NLq81KXcg6AmcC+yWkh4DzitlsDhPgcDMGqcpAsG3Nzu05M+cG9+8o10FgrJOH00f+KeWswwzs6bQHvv+S1XWQCDpEYrcfxERe5azXDOz+mqPff+lKvcNZacV7K8LHAZUlLlMM7N6y/MTysrdNVTznoG/SfprOcs0M2sIdw2VSY07jDsAw4F/K2eZZmYNUVnGiTOtXbm7hmbw2braFcAbZI9YMzNrVdw1VCYR4ZXRzKxN8GBxGUnaFhhCNlgMQERMLHe5Zmb14TGCMpF0LrA7WSC4F9gPeILsIcxmZq1GnruGyr3W0OFk62+/GxHHAUOBLmUu08ys3iKi5K29KXfX0CcRUSWpQlI3smd0bl7mMs3M6q0yxy2CcgeC6ZI2Aq4im0H0MfB0mcs0M6u3PHcNlS0QpIctXxQRS4E/SroP6BYRL5SrTDOzhmqPXT6lKlsgiIiQdCfZTWRExD/LVZaZWWPluUVQ7sHiJyXtWOYyzMwaLc9PKCv3GMEewPGS/gksJ7vDOCJiuzKXa2ZWL3leYqIsLQJJm6bd/chmCe0JHET2zOKDylGmmVljVBElb7WRNEDSI5JeljRb0qkpvaekByXNST97FOQ5U9JcSa9K2rcgfbikWenY5WnsFUldJN2c0p+SNLAx771cXUN3AkTEm8BvI+LNwq1MZZqZNVhTBQKyddV+HBFfAnYGTpI0BDgDmBoRg4Gp6TXp2BhgG2AUcIWkjulaVwLjgcFpG5XSxwFLImJL4FLg4sa893IFgsLHuPm+ATNr9ZrqhrKIWBARz6b9j4CXgX7AaOC6dNp1wCFpfzQwKSI+jYg3gLnACEl9yWZaTous0Ik18lRf6zZgZHVroSHKFQhiLftmZq1SfVoEksZLml6wjS92zdRl8xXgKWCTiFgAWbAANk6n9QPeLsg2L6X1S/s109fIExEVwDKgV0Pfe7kGi4dK+pCsZdA17cNng8XdylSumVmD1Gc2UERMACbUdo6kDYD/Bf4jIj6s5Qt7sQNRS3pteRqkLIEgIjrWfZaZWetRGU23ELWkdciCwF8i4vaU/J6kvhGxIHX7vJ/S5wEDCrL3B+an9P5F0gvzzJPUCegOLG5ofct9H4GZWZvQVGMEqa/+auDliPhtwaHJwNi0Pxa4qyB9TJoJNIhsUPjp1H30kaSd0zWPrZGn+lqHAw9HI26NLvvzCMzM2oImvLP4q8B3gFmSZqa0nwG/BG6RNA54CzgCICJmS7oFeIlsxtFJEVGZ8p0AXAt0BaakDbJAc72kuWQtgTGNqbBa6/oanTr3a50VM7NWp2LlOw2eMVNtu3/bpeTPnBfendbo8loTtwjMzICqVvqluDk4EJiZ4UdVmpnlXlPOGmprHAjMzHDXkJlZ7rlryMws59wiMDPLObcIzMxyrnL1PVz540BgZoYfXm9mlnt5fni9A4GZGW4RmJnlnmcNmZnlnGcNmZnlnJeYMDPLOY8RmJnlnMcIzMxyzi0CM7Oc830EZmY55xaBmVnOedaQmVnOebDYzCzn3DVkZpZzvrPYzCzn3CIwM8u5PI8RKM9RsK2QND4iJrR0Pax18d+FNZUOLV0BK8n4lq6AtUr+u7Am4UBgZpZzDgRmZjnnQNA2uB/YivHfhTUJDxabmeWcWwRmZjnnQGBmlnMOBGUmKSRdUvD6NEk/b+Y6PCpph+Ys0+pHUqWkmQXbwDKU8U9JvZv6utb2+c7i8vsU+KakiyJiUX0zS+oUERVlqJe1Lp9ExPbFDkgS2XheftdJtrJyi6D8Kshmd/yw5gFJm0maKumF9HPTlH6tpN9KegS4OL2+UtIjkl6X9A1Jf5b0sqRrC653paTpkmZLOq+53qA1PUkD0+/3CuBZYMDafr+F3/Ql7SDp0bTfS9IDkp6T9D+AWuK9WOvnQNA8/gAcLal7jfTfAxMjYjvgL8DlBce2AvaKiB+n1z2APckCyt3ApcA2wJclbZ/OOSsidgC2A74habtyvBkri64F3UJ3pLQvkv19fCUi3qT+v99zgSci4ivAZGDTstXe2jQHgmYQER8CE4FTahzaBbgx7V8PfK3g2K0RUVnw+u7I5vrOAt6LiFmpq2A2MDCdc6SkZ4HnyILEkCZ9I1ZOn0TE9mk7NKW9GRFPFpxT39/vbsANABFxD7CkqStt7YPHCJrPZWRN/GtqOafwpo7lNY59mn5WFexXv+4kaRBwGrBjRCxJXUbrNqbC1uJW/w3U8fut4LMvdTV/575RyOrkFkEziYjFwC3AuILkvwNj0v7RwBONKKIb2QfHMkmbAPs14lrW+tT2+/0nMDztH1aQ/hjZ3xWS9iPrXjT7HAeC5nUJUDh97xTgOEkvAN8BTm3ohSPiebIug9nAn4G/NaKe1srU8fs9D/idpMeByhrpu6XupH2At5qputbGeIkJM7Occ4vAzCznHAjMzHLOgcDMLOccCMzMcs6BwMws5xwI7HMKVsJ8UdKtktZrxLWulXR42v+TpLXeDStpd0m7NqCMoqtqlrLapqSP61nWzyWdVt86mrVmDgRWTPVyB9sCK4HjCw9K6tiQi0bE9yLipVpO2R2odyAws8ZxILC6PA5smb6tPyLpRmCWpI6Sfi3pmbR66vchWzJZ0u8lvSTpHmDj6gsVPhdB0ihJz0p6Pq28OpAs4PwwtUa+LqmPpP9NZTwj6aspb71X1ZR0p6QZaeXO8TWOXZLqMlVSn5S2haT7Up7HJW1d5JqnpPf5gqRJDfz3NWtxXmvI1kpSJ7KlDO5LSSOAbSPijfRhuiwidpTUBfibpAeAr5CtmvllYBPgJbI7YQuv2we4CtgtXatnRCyW9Efg44j4TTrvRuDSiHhC2RLd9wNf4rNVNc+XdACwxgf7Wnw3ldEVeEbS/0bEB8D6wLMR8WNJ56Rr/4Bs6fDjI2KOpJ2AK8hWfy10BjAoIj6VtFEp/6ZmrZEDgRXTVdLMtP84cDVZl83TEfFGSt8H2K66/x/oDgwmW/HyprRy6nxJDxe5/s7AY9XXSuswFbMXMERa/YW/m6QNUxnfTHnvkVTKqpqnSKpe1XNAqusHZIv23ZzSbwBul7RBer+3FpTdpcg1XwD+IulO4M4S6mDWKjkQWDGfe1pW+kAsXBFVwMkRcX+N8/an7hUvVcI5kHVd7hIRnxSpS8lro0janSyo7BIRK9KDW9a2Mmukcpeu7YlhBQ4gC0oHA/8paRs/Tc7aIo8RWEPdD5wgaR0ASVtJWp9sxcsxaQyhL7BHkbzTyB6sMijl7ZnSPwI2LDjvAbJuGtJ526fd+q6q2R1YkoLA1mQtkmodgOpWzbfJupw+BN6QdEQqQ5KGFl5QUgdgQEQ8AvwU2AjYoI56mLVKbhFYQ/2J7IE4zyr7ir4QOAS4g6wvfRbwGvDXmhkjYmEaY7g9faC+D+xN9uS12ySNBk4mW531D2l11k5kAeB4slU1b0qrav6VulfVvA84Pl3nVaDwYS/LgW0kzQCWAUel9KOBKyWdDawDTAKeL8jXEbhB2VPnRDaWsbSOepi1Sl591Mws59w1ZGaWcw4EZmY550BgZpZzDgRmZjnnQGBmlnMOBGZmOedAYGaWc/8fJPOneqHlT0IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "ax=plt.subplot()\n",
    "sns.heatmap(conf_matrix,annot=True,ax=ax,fmt='g')#annot=True to annotate cells, fmt='g' numbers not scientific form\n",
    "ax.set_xlabel('Predicted labels'); ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Normal', 'Fraud']); ax.yaxis.set_ticklabels(['Normal', 'Fraud']);\n",
    "ax.set(yticks=[0, 2], \n",
    "       xticks=[0.5, 1.5])\n",
    "ax.yaxis.set_major_locator(ticker.IndexLocator(base=1, offset=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nh2xw3tcfng9"
   },
   "source": [
    "##Second method: using encoder part of autoencoder and k-NN\n",
    "\n",
    "We train using all cases (fraud/non-fraud)in train dataset and use the result to map the instances into a 12-dimensional space. The mapped cases are fed to k-NN for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "B7SnYf1KFVm9",
    "outputId": "dbeb5d25-878e-4684-d802-734557fff4b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1113/1113 [==============================] - 24s 19ms/step - loss: 1.0524 - val_loss: 0.9414\n",
      "Epoch 2/100\n",
      " 542/1113 [=============>................] - ETA: 4s - loss: 0.9272"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-6ee72cd6de6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mautoencoder_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer_all\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoded_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mautoencoder_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m autoencoder_all.fit(X_train, X_train, epochs = 100, batch_size=128,\n\u001b[0m\u001b[0;32m      7\u001b[0m validation_data=(X_train,X_train))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1553\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_load_initial_step_from_ckpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m                     )\n\u001b[1;32m-> 1555\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1556\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[0;32m   1557\u001b[0m                             \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m             \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m             can_run_full_execution = (\n\u001b[0;32m   1376\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \"\"\"\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mno_copy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mforward_compat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_compatible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2022\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mgen_resource_variable_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_copy_on_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0m\u001b[0;32m    695\u001b[0m           self.handle, self._dtype)\n\u001b[0;32m    696\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    522\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    525\u001b[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0;32m    526\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_layer_all = Input(shape=(29, ))\n",
    "encoded_all = Dense(12,activation='tanh')(input_layer_all)\n",
    "decoded_all = Dense(29,activation='sigmoid')(encoded_all)\n",
    "autoencoder_all = Model(input_layer_all,decoded_all)\n",
    "autoencoder_all.compile(optimizer='adam',loss='mean_squared_error')\n",
    "autoencoder_all.fit(X_train, X_train, epochs = 100, batch_size=128,\n",
    "validation_data=(X_train,X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MntASWT9EYJ"
   },
   "outputs": [],
   "source": [
    "encoder_all = Model(input_layer_all,encoded_all)\n",
    "enc_all = encoder_all.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYRDsZ6ygSJq"
   },
   "source": [
    "Loading library for k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iix7bOJQ5gxc"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaDHQXxt5iCg"
   },
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "YjqB805u9XqF",
    "outputId": "28832207-2428-4477-973e-760c44169ee8"
   },
   "outputs": [],
   "source": [
    "# Train the model using the training sets\n",
    "knn_model.fit(enc_all,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "80H7xbeSBvWc",
    "outputId": "ff0fe410-fda3-4ca8-ebbf-108b745579ce"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "knn_predicted= knn_model.predict(encoder_all.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "6aVN3Qe-D3Oz",
    "outputId": "33126592-8277-4c98-8167-4be8a5159c2a"
   },
   "outputs": [],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_test,knn_predicted)\n",
    "\n",
    "ax=plt.subplot()\n",
    "sns.heatmap(conf_matrix,annot=True,ax=ax,fmt='g')#annot=True to annotate cells, fmt='g' numbers not scientific form\n",
    "ax.set_xlabel('Predicted labels'); ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Normal', 'Fraud']); ax.yaxis.set_ticklabels(['Normal', 'Fraud']);\n",
    "ax.set(yticks=[0, 2], \n",
    "       xticks=[0.5, 1.5])\n",
    "ax.yaxis.set_major_locator(ticker.IndexLocator(base=1, offset=0.5))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
